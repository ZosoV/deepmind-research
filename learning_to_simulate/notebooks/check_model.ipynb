{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Down the Training Model: `model_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposes of this notebook is to understand the model used during the training. The last objetivo to figure out how works `get_one_step_estimator_fn(data_path, noise_std)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from learning_to_simulate.train import *\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import graph_nets as gn\n",
    "import sonnet as snt\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_metadata(data_path):\n",
    "  with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "    return json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module: `EncodeProcessDecode`\n",
    "\n",
    "For defining the module, it is needed to use sonnet library. The sonnet abstract module, in this version, has two important function the `__init__` where all the known values are loaded, and the `_build()` which is executed when an instance of this class is called with some parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "    hidden_size: int, num_hidden_layers: int, output_size: int) -> snt.Module:\n",
    "  \"\"\"Builds an MLP.\"\"\"\n",
    "  return snt.nets.MLP(\n",
    "      output_sizes=[hidden_size] * num_hidden_layers + [output_size])\n",
    "\n",
    "\n",
    "class EncodeProcessDecode(snt.AbstractModule):\n",
    "  \"\"\"Encode-Process-Decode function approximator for learnable simulator.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      latent_size: int,\n",
    "      mlp_hidden_size: int,\n",
    "      mlp_num_hidden_layers: int,\n",
    "      num_message_passing_steps: int,\n",
    "      output_size: int,\n",
    "      name: str = \"EncodeProcessDecode\"):\n",
    "    \"\"\"Inits the model.\n",
    "\n",
    "    Args:\n",
    "      latent_size: Size of the node and edge latent representations.\n",
    "      mlp_hidden_size: Hidden layer size for all MLPs.\n",
    "      mlp_num_hidden_layers: Number of hidden layers in all MLPs.\n",
    "      num_message_passing_steps: Number of message passing steps.\n",
    "      output_size: Output size of the decode node representations as required\n",
    "        by the downstream update function.\n",
    "      name: Name of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self._latent_size = latent_size\n",
    "    self._mlp_hidden_size = mlp_hidden_size\n",
    "    self._mlp_num_hidden_layers = mlp_num_hidden_layers\n",
    "    self._num_message_passing_steps = num_message_passing_steps\n",
    "    self._output_size = output_size\n",
    "\n",
    "    with self._enter_variable_scope():\n",
    "      self._networks_builder()\n",
    "\n",
    "  def _build(self, input_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
    "    \"\"\"Forward pass of the learnable dynamics model.\"\"\"\n",
    "\n",
    "    # Encode the input_graph.\n",
    "    latent_graph_0 = self._encode(input_graph)\n",
    "\n",
    "    # Do `m` message passing steps in the latent graphs.\n",
    "    latent_graph_m = self._process(latent_graph_0)\n",
    "\n",
    "    # Decode from the last latent graph.\n",
    "    return self._decode(latent_graph_m)\n",
    "\n",
    "  def _networks_builder(self):\n",
    "    \"\"\"Builds the networks.\"\"\"\n",
    "\n",
    "    def build_mlp_with_layer_norm():\n",
    "      # returns a mlp sonnet module with layers \n",
    "      # = [hidden_size] * num_hidden_layers + [output_size]\n",
    "      mlp = build_mlp(\n",
    "          hidden_size=self._mlp_hidden_size,\n",
    "          num_hidden_layers=self._mlp_num_hidden_layers,\n",
    "          output_size=self._latent_size)\n",
    "      #adding a final normal layer\n",
    "      return snt.Sequential([mlp, snt.LayerNorm()])\n",
    "\n",
    "    # The encoder graph network independently encodes edge and node features.\n",
    "    encoder_kwargs = dict(\n",
    "        edge_model_fn=build_mlp_with_layer_norm,\n",
    "        node_model_fn=build_mlp_with_layer_norm)\n",
    "    self._encoder_network = gn.modules.GraphIndependent(**encoder_kwargs)\n",
    "\n",
    "    # Create `num_message_passing_steps` graph networks with unshared parameters\n",
    "    # that update the node and edge latent features.\n",
    "    # Note that we can use `modules.InteractionNetwork` because\n",
    "    # it also outputs the messages as updated edge latent features.\n",
    "    self._processor_networks = []\n",
    "    for _ in range(self._num_message_passing_steps):\n",
    "      self._processor_networks.append(\n",
    "          gn.modules.InteractionNetwork(\n",
    "              edge_model_fn=build_mlp_with_layer_norm,\n",
    "              node_model_fn=build_mlp_with_layer_norm))\n",
    "\n",
    "    # The decoder MLP decodes node latent features into the output size.\n",
    "    self._decoder_network = build_mlp(\n",
    "        hidden_size=self._mlp_hidden_size,\n",
    "        num_hidden_layers=self._mlp_num_hidden_layers,\n",
    "        output_size=self._output_size)\n",
    "\n",
    "  def _encode(\n",
    "      self, input_graph: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
    "    \"\"\"Encodes the input graph features into a latent graph.\"\"\"\n",
    "\n",
    "    # Copy the globals to all of the nodes, if applicable.\n",
    "    if input_graph.globals is not None:\n",
    "      broadcasted_globals = gn.blocks.broadcast_globals_to_nodes(input_graph)\n",
    "      input_graph = input_graph.replace(\n",
    "          nodes=tf.concat([input_graph.nodes, broadcasted_globals], axis=-1),\n",
    "          globals=None)\n",
    "\n",
    "    # Encode the node and edge features.\n",
    "    latent_graph_0 = self._encoder_network(input_graph)\n",
    "    return latent_graph_0\n",
    "\n",
    "  def _process(\n",
    "      self, latent_graph_0: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
    "    \"\"\"Processes the latent graph with several steps of message passing.\"\"\"\n",
    "\n",
    "    # Do `m` message passing steps in the latent graphs.\n",
    "    # (In the shared parameters case, just reuse the same `processor_network`)\n",
    "    latent_graph_prev_k = latent_graph_0\n",
    "    for processor_network_k in self._processor_networks:\n",
    "      latent_graph_k = self._process_step(\n",
    "          processor_network_k, latent_graph_prev_k)\n",
    "      latent_graph_prev_k = latent_graph_k\n",
    "\n",
    "    latent_graph_m = latent_graph_k\n",
    "    return latent_graph_m\n",
    "\n",
    "  def _process_step(\n",
    "      self, processor_network_k: snt.Module,\n",
    "      latent_graph_prev_k: gn.graphs.GraphsTuple) -> gn.graphs.GraphsTuple:\n",
    "    \"\"\"Single step of message passing with node/edge residual connections.\"\"\"\n",
    "\n",
    "    # One step of message passing.\n",
    "    latent_graph_k = processor_network_k(latent_graph_prev_k)\n",
    "\n",
    "    # Add residuals. \n",
    "    # To the new graph add residual information of nodes and edges\n",
    "    # of the prev graph\n",
    "    latent_graph_k = latent_graph_k.replace(\n",
    "        nodes=latent_graph_k.nodes+latent_graph_prev_k.nodes,\n",
    "        edges=latent_graph_k.edges+latent_graph_prev_k.edges)\n",
    "    return latent_graph_k\n",
    "\n",
    "  def _decode(self, latent_graph: gn.graphs.GraphsTuple) -> tf.Tensor:\n",
    "    \"\"\"Decodes from the latent graph.\"\"\"\n",
    "    return self._decoder_network(latent_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Define some global variables\n",
    "data_path = \"../../information/datasets/WaterDropSample\"\n",
    "model_path = \"../../information/models/WaterDropSample\"\n",
    "\n",
    "noise_std = 6.7e-4\n",
    "batch_size = 2\n",
    "num_steps = 2\n",
    "    \n",
    "# To train this model, the authors uses an estimator, which is another way \n",
    "# to define a model in tensorflow; it is like a wrapper of the model\n",
    "# It needs two principal components: \n",
    "#     input_fn: input function that return a tf.data.Dataset\n",
    "#     model_fn: model function that defines the architecture structure.     \n",
    "model_fn = get_one_step_estimator_fn(data_path, noise_std)\n",
    "estimator = tf.estimator.Estimator(model_fn = model_fn,model_dir=model_path)\n",
    "\n",
    "input_fn = get_input_fn(data_path, batch_size,\n",
    "                            mode='one_step_train', split='train')\n",
    "\n",
    "estimator.train(\n",
    "      input_fn= input_fn,\n",
    "      max_steps=num_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to break down the function to understand the working of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': [[0.1, 0.9], [0.1, 0.9]],\n",
       " 'sequence_length': 1000,\n",
       " 'default_connectivity_radius': 0.015,\n",
       " 'dim': 2,\n",
       " 'dt': 0.0025,\n",
       " 'vel_mean': [-3.964619574176163e-05, -0.00026272129664401046],\n",
       " 'vel_std': [0.0013722809722366911, 0.0013119977252142715],\n",
       " 'acc_mean': [2.602686518497945e-08, 1.0721623948191945e-07],\n",
       " 'acc_std': [6.742962470925277e-05, 8.700719180424815e-05]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = _read_metadata(data_path)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latent_size': (128,), 'mlp_hidden_size': (128,), 'mlp_num_hidden_layers': (2,), 'num_message_passing_steps': 10}\n",
      "{'latent_size': (128,), 'mlp_hidden_size': (128,), 'mlp_num_hidden_layers': (2,), 'num_message_passing_steps': 10}\n"
     ]
    }
   ],
   "source": [
    "latent_size=128,\n",
    "hidden_size=128,\n",
    "hidden_layers=2,\n",
    "message_passing_steps=10\n",
    "model_kwargs = dict(\n",
    "  latent_size=latent_size,\n",
    "  mlp_hidden_size=hidden_size,\n",
    "  mlp_num_hidden_layers=hidden_layers,\n",
    "  num_message_passing_steps=message_passing_steps)\n",
    "print(model_kwargs)\n",
    "def func_keyword_arg(**kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "func_keyword_arg(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.0, 10.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "a = tf.placeholder(dtype=tf.float32,shape=(), name='a')\n",
    "d = tf.placeholder(dtype=tf.float32,shape=(), name='d')\n",
    "b = tf.get_variable(name='b', initializer=tf.zeros_like(d)) #, use_resource = True)\n",
    "c=a+b\n",
    "b_init = tf.assign(b, d)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())   \n",
    "    print(sess.run([c,b_init,b], feed_dict={a:5.,d:10.})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-simulate': conda)",
   "language": "python",
   "name": "python36964bitlearnsimulateconda90aa6482bbb549ebbaef506b2225e634"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
