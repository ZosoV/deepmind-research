{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "general-examination",
   "metadata": {},
   "source": [
    "## Checking Special Functions\n",
    "This notebook intends to explain the behavior of some special functions, which are used during the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-walnut",
   "metadata": {},
   "source": [
    "Import some important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "separated-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import json\n",
    "import numpy as np\n",
    "from learning_to_simulate import reading_utils\n",
    "from learning_to_simulate import train\n",
    "from learning_to_simulate import learned_simulator\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-marina",
   "metadata": {},
   "source": [
    "Define the function to read the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shaped-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_metadata(data_path):\n",
    "  with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "    return json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-marina",
   "metadata": {},
   "source": [
    "Load the input data using the `input_fn()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _yield_value at 0x7feb896ddea0> appears to be a generator function. It will not be converted by AutoGraph.\n",
      "WARNING: Entity <function _yield_value at 0x7feb896ddea0> appears to be a generator function. It will not be converted by AutoGraph.\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"/home/zoso/Documents/deepmind-research/information\"\n",
    "data_path = os.path.join(info_dir,'datasets/WaterDropSample/')\n",
    "\n",
    "batch_size = 2\n",
    "mode = 'one_step_train'\n",
    "split = 'train'\n",
    "\n",
    "input_fn = train.get_input_fn(data_path, batch_size,mode=mode, split=split)\n",
    "\n",
    "dataset = input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-hollywood",
   "metadata": {},
   "source": [
    "Now, we are going to use some special function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-indonesian",
   "metadata": {},
   "source": [
    "## Get the velocities from positions\n",
    "    \n",
    "$$\\dot{p}^{t_k} = p^{t_k} - p^{t_{k-1}}  $$\n",
    "\n",
    "`time_diff` just gets the difference between the next and previous positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "funny-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle types: \n",
      "tf.Tensor([5 5], shape=(2,), dtype=int64)\n",
      "Positions one particle: \n",
      "tf.Tensor(\n",
      "[[[0.7872539  0.16003212]\n",
      "  [0.78718716 0.15989359]\n",
      "  [0.7871062  0.15974379]\n",
      "  [0.7870073  0.1595886 ]\n",
      "  [0.7868904  0.15943238]\n",
      "  [0.7867547  0.15928067]]\n",
      "\n",
      " [[0.75501305 0.15070474]\n",
      "  [0.75471425 0.15050365]\n",
      "  [0.7543989  0.15029311]\n",
      "  [0.7540701  0.15008163]\n",
      "  [0.7537295  0.14987446]\n",
      "  [0.7533809  0.14967577]]], shape=(2, 6, 2), dtype=float32)\n",
      "Velocities one particle: \n",
      "tf.Tensor(\n",
      "[[[-6.6757202e-05 -1.3853610e-04]\n",
      "  [-8.0943108e-05 -1.4980137e-04]\n",
      "  [-9.8943710e-05 -1.5518069e-04]\n",
      "  [-1.1688471e-04 -1.5622377e-04]\n",
      "  [-1.3566017e-04 -1.5170872e-04]]\n",
      "\n",
      " [[-2.9879808e-04 -2.0109117e-04]\n",
      "  [-3.1536818e-04 -2.1053851e-04]\n",
      "  [-3.2877922e-04 -2.1147728e-04]\n",
      "  [-3.4058094e-04 -2.0717084e-04]\n",
      "  [-3.4862757e-04 -1.9869208e-04]]], shape=(2, 5, 2), dtype=float32)\n",
      "Num nodes per examples: \n",
      "tf.Tensor([678 678], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in dataset.take(1):\n",
    "    particle_type = features['particle_type'][:2]\n",
    "    position_sequence = features['position'][:2]\n",
    "    velocity_sequence = learned_simulator.time_diff(features['position'])[:2]\n",
    "    n_particles_per_example = features['n_particles_per_example']\n",
    "    print(\"Particle types: \")\n",
    "    print(particle_type)\n",
    "    print(\"Positions one particle: \")\n",
    "    print(position_sequence)\n",
    "    print(\"Velocities one particle: \")\n",
    "    print(velocity_sequence)\n",
    "    print(\"Num nodes per examples: \")\n",
    "    print(n_particles_per_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-elements",
   "metadata": {},
   "source": [
    "In the next, cells we are going to do experiment only over two particles for understanding the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-establishment",
   "metadata": {},
   "source": [
    "## Noise Injection - Random Walk\n",
    "For each input state, particle and spatial dimension. It is performed the following steps\n",
    "\n",
    "1. Accumulate across time\n",
    "2. Random Walk\n",
    "3. Pertud the stack velocities (updated the velocities)\n",
    "4. Adjust the position features to mantained $\\dot{p}^{t_k} = p^{t_k} - p^{t_{k-1}}$ for consistency\n",
    "\n",
    "This method adds noise to each input, adding always noise to the previous state in sequence as in a random walk.\n",
    "\n",
    "In this way, it seeks to simulate the accumulation of error in a rolllout.\n",
    "\n",
    "Take in mind the concept of [random walk](https://en.wikipedia.org/wiki/Random_walk#:~:text=In%20mathematics%2C%20a%20random%20walk,space%20such%20as%20the%20integers.).\n",
    "In mathematics, a random walk is a mathematical object, known as a stochastic or random process, that describes a path that consists of a succession of random steps on some mathematical space such as the integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broad-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity_sequence_noise: \n",
      "tf.Tensor(\n",
      "[[[ 1.3896731e-04  2.9208095e-04]\n",
      "  [-4.3777040e-05 -2.0929029e-04]\n",
      "  [ 2.5434262e-04  6.6257853e-05]\n",
      "  [-5.8383623e-04 -3.3508120e-05]\n",
      "  [-3.7062203e-04  2.6564026e-05]]\n",
      "\n",
      " [[-9.1758535e-05  2.6945927e-04]\n",
      "  [-3.9058787e-04 -9.2792856e-05]\n",
      "  [ 2.8277788e-04  1.6330833e-04]\n",
      "  [ 1.8657474e-05 -1.4110726e-04]\n",
      "  [ 9.1974624e-04 -3.8296484e-06]]], shape=(2, 5, 2), dtype=float32)\n",
      "---------------------\n",
      "velocity_sequence_noise after random walk: \n",
      "tf.Tensor(\n",
      "[[[ 1.38967313e-04  2.92080949e-04]\n",
      "  [ 9.51902766e-05  8.27906624e-05]\n",
      "  [ 3.49532900e-04  1.49048516e-04]\n",
      "  [-2.34303327e-04  1.15540395e-04]\n",
      "  [-6.04925328e-04  1.42104429e-04]]\n",
      "\n",
      " [[-9.17585348e-05  2.69459269e-04]\n",
      "  [-4.82346397e-04  1.76666421e-04]\n",
      "  [-1.99568516e-04  3.39974766e-04]\n",
      "  [-1.80911040e-04  1.98867507e-04]\n",
      "  [ 7.38835195e-04  1.95037865e-04]]], shape=(2, 5, 2), dtype=float32)\n",
      "---------------------\n",
      "position sequence noise: \n",
      "tf.Tensor(\n",
      "[[[ 0.0000000e+00  0.0000000e+00]\n",
      "  [ 1.3896731e-04  2.9208095e-04]\n",
      "  [ 2.3415759e-04  3.7487160e-04]\n",
      "  [ 5.8369047e-04  5.2392011e-04]\n",
      "  [ 3.4938715e-04  6.3946052e-04]\n",
      "  [-2.5553818e-04  7.8156497e-04]]\n",
      "\n",
      " [[ 0.0000000e+00  0.0000000e+00]\n",
      "  [-9.1758535e-05  2.6945927e-04]\n",
      "  [-5.7410495e-04  4.4612569e-04]\n",
      "  [-7.7367347e-04  7.8610046e-04]\n",
      "  [-9.5458451e-04  9.8496792e-04]\n",
      "  [-2.1574931e-04  1.1800057e-03]]], shape=(2, 6, 2), dtype=float32)\n",
      "---------------------\n",
      "non_kinematic_mask: \n",
      "tf.Tensor([ True  True], shape=(2,), dtype=bool)\n",
      "---------------------\n",
      "noise_mask: \n",
      "tf.Tensor(\n",
      "[[[1.]]\n",
      "\n",
      " [[1.]]], shape=(2, 1, 1), dtype=float32)\n",
      "---------------------\n",
      "Apply the mask to the noise\n",
      "tf.Tensor(\n",
      "[[[ 0.0000000e+00  0.0000000e+00]\n",
      "  [ 1.3896731e-04  2.9208095e-04]\n",
      "  [ 2.3415759e-04  3.7487160e-04]\n",
      "  [ 5.8369047e-04  5.2392011e-04]\n",
      "  [ 3.4938715e-04  6.3946052e-04]\n",
      "  [-2.5553818e-04  7.8156497e-04]]\n",
      "\n",
      " [[ 0.0000000e+00  0.0000000e+00]\n",
      "  [-9.1758535e-05  2.6945927e-04]\n",
      "  [-5.7410495e-04  4.4612569e-04]\n",
      "  [-7.7367347e-04  7.8610046e-04]\n",
      "  [-9.5458451e-04  9.8496792e-04]\n",
      "  [-2.1574931e-04  1.1800057e-03]]], shape=(2, 6, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# We want the noise scale in the velocity at the last step to be fixed.\n",
    "# Because we are going to compose noise at each step using a random_walk:\n",
    "# std_last_step**2 = num_velocities * std_each_step**2\n",
    "# so to keep `std_last_step` fixed, we apply at each step:\n",
    "# std_each_step `std_last_step / np.sqrt(num_input_velocities)`\n",
    "# TODO(alvarosg): Make sure this is consistent with the value and\n",
    "# description provided in the paper.\n",
    "noise_std_last_step = 6.7e-4 # standard_noise # defined in FLAG arguments\n",
    "\n",
    "num_velocities = velocity_sequence.shape.as_list()[1]\n",
    "velocity_sequence_noise = tf.random.normal(\n",
    "  tf.shape(velocity_sequence),\n",
    "  stddev=noise_std_last_step / num_velocities ** 0.5,\n",
    "  dtype=position_sequence.dtype)\n",
    "print(\"velocity_sequence_noise: \")\n",
    "print(velocity_sequence_noise)\n",
    "\n",
    "print(\"---------------------\")\n",
    "# Apply the random walk. # cumulative sum # tf.cumsum([a, b, c])   # [a, a + b, a + b + c]\n",
    "velocity_sequence_noise = tf.cumsum(velocity_sequence_noise, axis=1)\n",
    "print(\"velocity_sequence_noise after random walk: \")\n",
    "print(velocity_sequence_noise)\n",
    "\n",
    "# Integrate the noise in the velocity to the positions, assuming\n",
    "# an Euler intergrator and a dt = 1, and adding no noise to the very first\n",
    "# position (since that will only be used to calculate the first position#\n",
    "# change.\n",
    "print(\"---------------------\")\n",
    "position_sequence_noise = tf.concat([\n",
    "  tf.zeros_like(velocity_sequence_noise[:, 0:1]),\n",
    "  tf.cumsum(velocity_sequence_noise, axis=1)], axis=1)\n",
    "print(\"position sequence noise: \")\n",
    "print(position_sequence_noise)\n",
    "\n",
    "print(\"---------------------\")\n",
    "sampled_noise = position_sequence_noise\n",
    "\n",
    "non_kinematic_mask = tf.logical_not(train.get_kinematic_mask(particle_type))\n",
    "print(\"non_kinematic_mask: \")\n",
    "print(non_kinematic_mask)\n",
    "\n",
    "print(\"---------------------\")\n",
    "noise_mask = tf.cast(\n",
    "    non_kinematic_mask, sampled_noise.dtype)[:, tf.newaxis, tf.newaxis]\n",
    "print(\"noise_mask: \")\n",
    "print(noise_mask)\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Apply the mask to the noise\") # just send to zero all the noise of a kinematic particle\n",
    "sampled_noise *= noise_mask\n",
    "print(sampled_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "blessed-magnitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36782, shape=(1,), dtype=int32, numpy=array([678], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_particles_per_example[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-perth",
   "metadata": {},
   "source": [
    "## Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-decline",
   "metadata": {},
   "source": [
    "Here, the author uses a k-d tree structure to deal with the points in n_dimension (max 3 dim for our proposes)\n",
    "\n",
    "In computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees. For further explanation see: [wiki](https://en.wikipedia.org/wiki/K-d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "rental-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 7  8]\n",
      "  [ 9 10]\n",
      "  [11 12]]], shape=(2, 3, 2), dtype=int32)\n",
      "----\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36809, shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sonnet as snt\n",
    "arr = tf.convert_to_tensor([[[1,2],[3,4],[5,6]],[[7,8],[9,10],[11,12]]])\n",
    "print(arr)\n",
    "print(\"----\")\n",
    "print(arr[0])\n",
    "print(\"----\")\n",
    "snt.MergeDims(start=1, size=2)(\n",
    "        arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "circular-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5.  6.]\n",
      " [11. 12.]], shape=(2, 2), dtype=float32)\n",
      "-----\n",
      "tf.Tensor(\n",
      "[[4. 5.]\n",
      " [6. 7.]], shape=(2, 2), dtype=float32)\n",
      "-----\n",
      "tf.Tensor([4. 6.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([[4. 6.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [7. 6.]], shape=(2, 2), dtype=float32)\n",
      "-----\n",
      "tf.Tensor(\n",
      "[[ 0.  1.]\n",
      " [-6. -5.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36967, shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 1.,  0.,  0.,  1.],\n",
       "       [ 7.,  6., -6., -5.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_sequence = tf.convert_to_tensor([[[1.,2.],[3.,4.],[5.,6.]],[[7.,8.],[9.,10.],[11.,12.]]])\n",
    "most_recent_position = position_sequence[:, -1]\n",
    "\n",
    "print(most_recent_position)\n",
    "\n",
    "b = np.array([[4.,5.],[6.,7.]])\n",
    "\n",
    "boundaries = tf.constant(b, dtype=tf.float32)\n",
    "print(\"-----\")\n",
    "print(boundaries)\n",
    "print(\"-----\")\n",
    "print(boundaries[:, 0])\n",
    "print(tf.expand_dims(boundaries[:, 0], 0))\n",
    "distance_to_lower_boundary = (\n",
    "    most_recent_position - tf.expand_dims(boundaries[:, 0], 0))\n",
    "print(distance_to_lower_boundary)\n",
    "distance_to_upper_boundary = (\n",
    "        tf.expand_dims(boundaries[:, 1], 0) - most_recent_position)\n",
    "print(\"-----\")\n",
    "print(distance_to_upper_boundary)\n",
    "tf.concat([distance_to_lower_boundary, distance_to_upper_boundary], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-simulate': conda)",
   "language": "python",
   "name": "python36964bitlearnsimulateconda90aa6482bbb549ebbaef506b2225e634"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
